# ğŸ“Š ETL Pipeline for Brokerage Notes with PDF Extraction, dbt-core & Streamlit Dashboard

This project is a complete **ETL (Extract, Transform, Load)** pipeline built in **Python**, designed to process and analyze **brokerage notes** in PDF format.

It enables automated extraction, transformation, and visualization of financial trading data using the following tools:

## ğŸ”§ Technologies Used

- **Python 3.12** â€“ The core programming language for all ETL and analytics logic.
- **[Camelot](https://camelot-py.readthedocs.io/)** â€“ Extracts tabular data from brokerage PDFs.
- **PostgreSQL** â€“ Relational database to store the extracted structured data.
- **[dbt-core](https://docs.getdbt.com/)** â€“ For transforming and modeling raw extracted data following analytics engineering best practices.
- **[Streamlit](https://streamlit.io/)** â€“ Creates an interactive and user-friendly dashboard to explore key financial metrics.

---

## ğŸ“‚ Project Structure
ETL-PDF-Extractor/ â”œâ”€â”€ dashboard/ # Streamlit app â”‚ â””â”€â”€ app.py â”œâ”€â”€ dbt/ # dbt-core models â”‚ â”œâ”€â”€ models/ â”‚ â”œâ”€â”€ dbt_project.yml â”œâ”€â”€ etl/ # ETL scripts (PDF parsing and loading to DB) â”‚ â”œâ”€â”€ extractor.py â”‚ â”œâ”€â”€ loader.py â”œâ”€â”€ .env # Environment variables (not committed) â”œâ”€â”€ poetry.lock â”œâ”€â”€ pyproject.toml â””â”€â”€ README.md


---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/seu-usuario/ETL-PDF-Extractor.git
cd ETL-PDF-Extractor
```

2. Install dependencies with Poetry
Make sure you have Poetry installed:
```bash
poetry install
```


3. Configure your environment
Create a .env file at the root with your PostgreSQL connection info:
```bash
DB_HOST=localhost
DB_NAME=etl_pdf
DB_USER=your_user
DB_PASSWORD=your_password
```
Note: While the dashboard no longer uses dotenv, this file is used by other scripts in the ETL.

## ğŸ› ï¸ Running the ETL Pipeline
Place your brokerage note PDFs in a designated folder (e.g., file/pdf/jornada or redrex)

Run the extractor to parse and load the raw data into PostgreSQL:
```bash
poetry run python src/start.py
```

Run dbt to transform raw data:
```bash
cd dbt_models/
dbt run
```
## ğŸ“Š Running the Dashboard
Once your data is extracted and transformed, launch the dashboard:
```bash
streamlit run dashboard/app.py
```
Youâ€™ll be able to:

- Filter by asset (mercadoria) and date

- See KPIs like total movimentation and quantity

- Visualize trends over time

- View the filtered raw data in a clean table

## ğŸ“Œ Why dbt?
We chose dbt-core to implement the "T" in ETL â€” making data transformations modular, version-controlled, and testable. It allows clear lineage tracking and is great for team collaboration.






